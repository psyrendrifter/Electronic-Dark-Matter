import matplotlib.pyplot as plt
import numpy as np
import math as m
import gzip

#v2.0
#Version Notes:
#This version requires only lhe file and pythia_vertex containing VERTD(e-) data
#We do NOT assume normalization. However, due to the peak in the pythia output, we remove the first reimannian segment contributed by the strip near zero from the normalization of the pythia output


#*********************************************************************
#								     *
#                  Pythia Vertex Distance Distribution               *
#               					             *
#                      (Directly from Pythia/Ma5)                    *
#              						             *
#								     *
#*********************************************************************

#this takes in a MadAnalysis5job.saf file containing a histogram with a VERTD histogram 

################################################
#Reading Data
################################################

with open('pythia_vertex/Output/_defaultset/MadAnalysis5job.saf') as f:
        content = f.readlines()
content = [x.strip() for x in content]
content = [x.split(" ") for x in content] #parses the .saf file and gets better format


p_dvertex = []
d_dvertex = 1000
norm = 0
width = 0

for i in range(len(content)):
    if len(content[i])>2 and content[i][1] == 'nbins': #using structure of .saf file
        d_dvertex = (float(content[i+1][ len(content[i+1])-1 ])-float(content[i+1][ len(content[i+1])-4 ]))/float(content[i+1][0])
        #finds bin width and assigns to d_dvertex
	#Note that we assume that the bin width is given in mm, as we plot rho_d (given in mm) and 		p_dvertex on the same plot
    if len(content[i])>6 and content[i][5] == 'event-weights':
        norm = float(content[i][0]) #get the total integrated luminosity? Whatever normalizes the distribution to unity

for i in range(len(content)):
    if content[i][0] == '<Data>':
        for j in range(100):
            p_dvertex.append(float(content[i+2+j][0])/(norm*d_dvertex)) #add a new value into our discrete distribution. p_dvertex ~ d_P/d_dvertex



################################################
# p_vertex Normalization
################################################
normtest = 0
for i in range(len(p_dvertex)-1):
    normtest+=p_dvertex[i+1]*d_dvertex
   
for i in range(len(p_dvertex)):
    p_dvertex[i]=p_dvertex[i]/normtest


################################################
# Debug Block
################################################
#print content
#print d_dvertex
#print normtest
#print p_dvertex


############################################
# Plotting
################################################
distances = np.linspace(0, len(p_dvertex)*d_dvertex, num = len(p_dvertex)) #The number of data points we have in increments of d_dvertex, so we can graph p_dvertex against distance
dx = distances[1]-distances[0]

for i in range(len(p_dvertex)):
    if i == 0:
        plt.errorbar(distances[i]+dx/2., p_dvertex[i]/10, fmt = 'ro', label = 'pythia output')
    else:
        plt.errorbar(distances[i]+dx/2., p_dvertex[i]/10, fmt = 'ro')
#plot of true distance travelled as given by pythia

#plt.xlim()
#plt.ylim()








#*********************************************************************
#								     *
#        Calculation of Expected Vertex Distance Distribution        *
#               (Uses an integral expression/transform of            *
#                distributions of momentum magnitude to              *
#              predict distance distribution in lab frame)           *
#								     *
#*********************************************************************


#First, we take in the momentum spectrum of the particle with pdg code 'pdg' from the lhe file:

#################################################
# Reading .lhe File
#################################################
pdg = '5000001' #we choose to look at the momentum distribution of the x

with gzip.open('Events/tof_0/unweighted_events.lhe.gz') as f:
        lheFile = f.readlines()
lheFile = [x.strip() for x in lheFile]
lheFile = [x.split(" ") for x in lheFile]


mass = 0
width = 0
N = 0
momenta = []

for i in range(len(lheFile)):
    if lheFile[i][0] == pdg and len(lheFile[i]) == 4:
        mass = float(lheFile[i][1])

    if len(lheFile[i]) == 5 and lheFile[i][1] == pdg:
        width = float(lheFile[i][2])*(5.068e12) #GeV -> 1/mm

    if len(lheFile[i]) == 20 and lheFile[i][2] == 'Number':
        N = float(lheFile[i][19])

    if lheFile[i][0] == pdg and len(lheFile[i]) == 26:
        momenta.append(m.sqrt(float(lheFile[i][19])**2+float(lheFile[i][20])**2+float(lheFile[i][21])**2))


#################################################
# Setting Distribution
#################################################
lengths = np.linspace(0, len(p_dvertex)*d_dvertex, num = len(p_dvertex)) #this must span the same length as the pythia vertex output

rho_d = [] #this will hold our values for the pdf of survival time

for x in lengths:
    rho_at_x = 0
    for p in momenta:
        rho_at_x += (m.e**(-x * width*mass/p) * width*mass/p)/N
    rho_d.append(rho_at_x)



################################################
#rho_d Normalization
################################################
norm = 0

for i in range(len(rho_d)-1):
    norm+=rho_d[i]*(lengths[i+1]-lengths[i])

for i in range(len(rho_d)):
    rho_d[i] = rho_d[i]/norm

################################################
#Debug Block
################################################
#print lheFile
#print
#plt.hist(momenta, bins = 100); plt.show()
#print norm
#print rho_d

################################################
#Plotting
################################################
plt.figure(1)
plt.title("pdf of distance: expected vs. pythia output")
plt.xlabel("length (mm)")
plt.ylabel("pdf of survival (1/mm)")

#plt.hist(list, bins=100, normed=1) #MG5 lhe output of tof

for i in range(len(lengths)):
    if i == 0:
        plt.errorbar(lengths[i], rho_d[i]/10, fmt = 'ko', label = 'expected distance travelled') 
    else:
        plt.errorbar(lengths[i], rho_d[i]/10, fmt = 'ko')
#Our expectation for tof based on dynamics

#plt.yscale('log')
plt.legend()
plt.show()

























